{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CogAIP_carracing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaYRKvDhxKB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c7e481c-b055-4803-c0a6-bb2f9568c0ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwqGhFxY0LrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa5c337-7407-407d-c329-f3eea238a917"
      },
      "source": [
        "!pwd\n",
        "%cd /content/gdrive/My Drive/WorldModelsExperiments/carracing\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/gdrive/My Drive/WorldModelsExperiments/carracing\n",
            "/content/gdrive/My Drive/WorldModelsExperiments/carracing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5vk2ViF4beQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae1cb79-c544-4b1b-fd20-6bdd6a66a856"
      },
      "source": [
        "!pip install Box2D\n",
        "!apt-get update\n",
        "!apt-get install -y xvfb #python-opengl\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install gym==0.9.4\n",
        "!pip install pyglet==1.3.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Box2D in /usr/local/lib/python3.6/dist-packages (2.3.10)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Ign:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [444 kB]\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,692 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [236 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [54.3 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,815 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,134 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,370 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,243 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [866 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [265 kB]\n",
            "Get:24 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [46.5 kB]\n",
            "Fetched 11.5 MB in 3s (4,579 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  xserver-common\n",
            "Recommended packages:\n",
            "  xfonts-base\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "The following packages will be upgraded:\n",
            "  xserver-common\n",
            "1 upgraded, 1 newly installed, 0 to remove and 67 not upgraded.\n",
            "Need to get 811 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 xserver-common all 2:1.19.6-1ubuntu4.8 [26.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8 [784 kB]\n",
            "Fetched 811 kB in 1s (1,221 kB/s)\n",
            "(Reading database ... 147148 files and directories currently installed.)\n",
            "Preparing to unpack .../xserver-common_2%3a1.19.6-1ubuntu4.8_all.deb ...\n",
            "Unpacking xserver-common (2:1.19.6-1ubuntu4.8) over (2:1.19.6-1ubuntu4.7) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.8_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.8) ...\n",
            "Setting up xserver-common (2:1.19.6-1ubuntu4.8) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.8) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.6/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Requirement already satisfied: gym==0.9.4 in /usr/local/lib/python3.6/dist-packages (0.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym==0.9.4) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.9.4) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym==0.9.4) (1.18.5)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.9.4) (1.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.9.4) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.9.4) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.9.4) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.9.4) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym==0.9.4) (0.16.0)\n",
            "Requirement already satisfied: pyglet==1.3.2 in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.3.2) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjENA4126T5l"
      },
      "source": [
        "try:\n",
        "    import pyvirtualdisplay\n",
        "    display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
        "except ImportError:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cr16kS95SZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60cc9f04-52cb-4dae-d364-73aac358d789"
      },
      "source": [
        "%tensorflow_version 1.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjD5RM-H45d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ae97a0-fdc0-46a5-c590-2fb25f63391a"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df2MekF18DAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de389922-a6c1-4bc4-a3cd-ebd67530daa7"
      },
      "source": [
        "!pip show pyglet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: pyglet\n",
            "Version: 1.3.2\n",
            "Summary: Cross-platform windowing and multimedia library\n",
            "Home-page: http://pyglet.readthedocs.org/en/latest/\n",
            "Author: Alex Holkner\n",
            "Author-email: Alex.Holkner@gmail.com\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: future\n",
            "Required-by: gym\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prWLwuwzrMza"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import gym"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndPh4oo-z5md",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "outputId": "70b415cc-0540-4346-aaa4-fe6ac5c7e60c"
      },
      "source": [
        "'''\n",
        "saves ~ 200 episodes generated from a random policy\n",
        "'''\n",
        "\n",
        "# import numpy as np\n",
        "# import random\n",
        "# import os\n",
        "# import gym\n",
        "\n",
        "from model import make_model\n",
        "\n",
        "MAX_FRAMES = 1000 # max length of carracing\n",
        "MAX_TRIALS = 200 # just use this to extract one trial.\n",
        "\n",
        "render_mode = False # for debugging.\n",
        "\n",
        "DIR_NAME = '/content/gdrive/My Drive/WorldModelsExperiments/carracing/Data'\n",
        "if not os.path.exists(DIR_NAME):\n",
        "    os.makedirs(DIR_NAME)\n",
        "\n",
        "model = make_model(load_model=False)\n",
        "\n",
        "total_frames = 0\n",
        "model.make_env(render_mode=render_mode, full_episode=True)\n",
        "for trial in range(MAX_TRIALS): # 200 trials per worker\n",
        "  try:\n",
        "    random_generated_int = random.randint(0, 2**31-1)\n",
        "    filename = DIR_NAME+\"/\"+str(random_generated_int)+\".npz\"\n",
        "    recording_obs = []\n",
        "    recording_action = []\n",
        "\n",
        "    np.random.seed(random_generated_int)\n",
        "    model.env.seed(random_generated_int)\n",
        "\n",
        "    # random policy\n",
        "    model.init_random_model_params(stdev=np.random.rand()*0.01)\n",
        "\n",
        "    model.reset()\n",
        "    obs = model.env.reset() # pixels\n",
        "\n",
        "    for frame in range(MAX_FRAMES):\n",
        "      if render_mode:\n",
        "        model.env.render(\"human\")\n",
        "      else:\n",
        "        model.env.render(\"rgb_array\")\n",
        "\n",
        "      recording_obs.append(obs)\n",
        "\n",
        "      z, mu, logvar = model.encode_obs(obs)\n",
        "      action = model.get_action(z)\n",
        "\n",
        "      recording_action.append(action)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "    total_frames += (frame+1)\n",
        "    print(\"dead at\", frame+1, \"total recorded frames for this worker\", total_frames)\n",
        "    recording_obs = np.array(recording_obs, dtype=np.uint8)\n",
        "    recording_action = np.array(recording_action, dtype=np.float16)\n",
        "    np.savez_compressed(filename, obs=recording_obs, action=recording_action)\n",
        "  except gym.error.Error:\n",
        "    print(\"stupid gym error, life goes on\")\n",
        "    model.env.close()\n",
        "    model.make_env(render_mode=render_mode)\n",
        "    continue\n",
        "model.env.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:21: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Model using cpu.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:34: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:37: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:44: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:47: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:53: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:90: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:92: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:104: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d5268514edc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIR_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtotal_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/WorldModelsExperiments/carracing/model.py\u001b[0m in \u001b[0;36mmake_model\u001b[0;34m(load_model)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;31m# can be extended in the future.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/WorldModelsExperiments/carracing/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load_model)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"carracing\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMDNRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, z_size, batch_size, learning_rate, kl_tolerance, is_training, reuse, gpu_mode)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model using gpu.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py\u001b[0m in \u001b[0;36m_init_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m\"\"\"Launch TensorFlow session and initialize variables\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclose_sess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;34m\"\"\" Close TensorFlow session \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDE3gXV4IVrw"
      },
      "source": [
        "'''\n",
        "Train VAE model on data created using extract.py\n",
        "final model saved into tf_vae/vae.json\n",
        "'''\n",
        "\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # can just override for multi-gpu systems\n",
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "np.set_printoptions(precision=4, edgeitems=6, linewidth=100, suppress=True)\n",
        "\n",
        "from vae.vae import ConvVAE, reset_graph\n",
        "\n",
        "# Hyperparameters for ConvVAE\n",
        "z_size=32\n",
        "batch_size=100\n",
        "learning_rate=0.0001\n",
        "kl_tolerance=0.5\n",
        "\n",
        "# Parameters for training\n",
        "NUM_EPOCH = 2\n",
        "DATA_DIR = \"/content/gdrive/My Drive/WorldModelsExperiments/carracing/Data\"\n",
        "\n",
        "model_save_path = \"/content/gdrive/My Drive/WorldModelsExperiments/carracing/vae\"\n",
        "if not os.path.exists(model_save_path):\n",
        "  os.makedirs(model_save_path)\n",
        "\n",
        "def count_length_of_filelist(filelist):\n",
        "  # although this is inefficient, much faster than doing np.concatenate([giant list of blobs])..\n",
        "  N = len(filelist)\n",
        "  total_length = 0\n",
        "  for i in range(N):\n",
        "    filename = filelist[i]\n",
        "    raw_data = np.load(os.path.join(DATA_DIR, filename))['obs']\n",
        "    l = len(raw_data)\n",
        "    total_length += l\n",
        "    if (i % 1000 == 0):\n",
        "      print(\"loading file\", i)\n",
        "  return  total_length\n",
        "\n",
        "def create_dataset(filelist, N=10000, M=1000): # N is 10000 episodes, M is number of timesteps\n",
        "  data = np.zeros((M*N, 64, 64, 3), dtype=np.uint8)\n",
        "  idx = 0\n",
        "  for i in range(N):\n",
        "    filename = filelist[i]\n",
        "    raw_data = np.load(os.path.join(DATA_DIR, filename))['obs']\n",
        "    l = len(raw_data)\n",
        "    if (idx+l) > (M*N):\n",
        "      data = data[0:idx]\n",
        "      print('premature break')\n",
        "      break\n",
        "    data[idx:idx+l] = raw_data\n",
        "    idx += l\n",
        "    if ((i+1) % 100 == 0):\n",
        "      print(\"loading file\", i+1)\n",
        "  return data\n",
        "\n",
        "# load dataset from record/*. only use first 10K, sorted by filename.\n",
        "filelist = os.listdir(DATA_DIR)\n",
        "filelist.sort()\n",
        "filelist = filelist[0:10000]\n",
        "#print(\"check total number of images:\", count_length_of_filelist(filelist))\n",
        "dataset = create_dataset(filelist)\n",
        "\n",
        "# split into batches:\n",
        "total_length = len(dataset)\n",
        "num_batches = int(np.floor(total_length/batch_size))\n",
        "print(\"num_batches\", num_batches)\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "vae = ConvVAE(z_size=z_size,\n",
        "              batch_size=batch_size,\n",
        "              learning_rate=learning_rate,\n",
        "              kl_tolerance=kl_tolerance,\n",
        "              is_training=True,\n",
        "              reuse=False,\n",
        "              gpu_mode=True)\n",
        "\n",
        "# train loop:\n",
        "print(\"train\", \"step\", \"loss\", \"recon_loss\", \"kl_loss\")\n",
        "for epoch in range(NUM_EPOCH):\n",
        "  np.random.shuffle(dataset)\n",
        "  for idx in range(num_batches):\n",
        "    batch = dataset[idx*batch_size:(idx+1)*batch_size]\n",
        "\n",
        "    obs = batch.astype(np.float)/255.0\n",
        "\n",
        "    feed = {vae.x: obs,}\n",
        "\n",
        "    (train_loss, r_loss, kl_loss, train_step, _) = vae.sess.run([\n",
        "      vae.loss, vae.r_loss, vae.kl_loss, vae.global_step, vae.train_op\n",
        "    ], feed)\n",
        "  \n",
        "    if ((train_step+1) % 500 == 0):\n",
        "      print(\"step\", (train_step+1), train_loss, r_loss, kl_loss)\n",
        "    if ((train_step+1) % 5000 == 0):\n",
        "      vae.save_json( model_save_path + \"/vae_self_{}.json\".format(NUM_EPOCH))\n",
        "\n",
        "# finished, final model:\n",
        "vae.save_json(model_save_path + \"/vae_self_{}.json\".format(NUM_EPOCH))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwjUSalWWvF-"
      },
      "source": [
        "data = np.load('/content/gdrive/MyDrive/WorldModelsExperiments/carracing/Data/1007209374.npz')\n",
        "frames = data['obs']\n",
        "frames = frames.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBoiR1S0Ybgy"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(precision=4, edgeitems=6, linewidth=100, suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN01cYapYcUj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "5983634f-368e-4c56-dd90-0d0bfe5ef368"
      },
      "source": [
        "# show recorded frame that will be fed into the input of VAE\n",
        "# for i in range(np.shape(frames)[0]):\n",
        "# import cv2\n",
        "# from google.colab.patches import cv2_imshow\n",
        "frame = random.choice(frames).astype(np.uint8)\n",
        "# np.moveaxis(frame, )\n",
        "fig = plt.figure('k')\n",
        "plt.imshow(frame)\n",
        "# cv2_imshow(frame)\n",
        "plt.show()\n",
        "# print(frame)\n",
        "# from PIL import Image\n",
        "# im = Image.fromarray(frame)\n",
        "# im.show()\n",
        "# print(frame[0,0,:])\n",
        "fig.savefig('frame.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C39RuPMrJbV"
      },
      "source": [
        "from vae.vae import ConvVAE, reset_graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPNf4lK9rK9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ad6f98-a2fd-4270-e8c3-18591b787fb9"
      },
      "source": [
        "z_size = 32\n",
        "model_path_name = '/content/gdrive/My Drive/WorldModelsExperiments/carracing/vae'\n",
        "vae = ConvVAE(z_size=z_size,\n",
        "              batch_size=1,\n",
        "              is_training=False,\n",
        "              reuse=False,\n",
        "              gpu_mode=False)\n",
        "\n",
        "vae.load_json(os.path.join(model_path_name, 'vae.json'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:21: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:24: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Model using cpu.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:34: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:37: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:44: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:47: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:53: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:90: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:92: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/WorldModelsExperiments/carracing/vae/vae.py:104: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDW43CTerpZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc989cc-fff9-4386-ad9a-cc1d8d590d03"
      },
      "source": [
        "batch_z = vae.encode(np.expand_dims(frame, 0))\n",
        "# print(np.shape(frame))\n",
        "print(batch_z[0]) # print out sampled z\n",
        "# print(np.shape(batch_z[0]))\n",
        "reconstruct = vae.decode(batch_z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    -7.3798    -28.6069   -198.996     -12.9388    -24.4604    130.9974     -8.7139    -17.5424\n",
            "     -7.2954   -135.2046     21.5702    -14.2117    -10.8446      8.1322   -102.4489    -93.9528\n",
            "     14.055     562.8981    295.5195      4.5995    148.3639    355.6322    -13.5248    -48.5271\n",
            "      6.8703     71.7277     79.3225    -10.0039   -188.2822   -174.3987      8.8268 -10629.584 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1jy0PGLsEIC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "038965bb-5a2e-42d3-c55a-d24ff5a8f2fb"
      },
      "source": [
        "fig = plt.figure('r')\n",
        "plt.imshow(reconstruct[0])\n",
        "plt.show()\n",
        "fig.savefig('rec.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "Ym8vNAd4MfLG",
        "outputId": "d63a248c-3b13-4198-d3b9-22e16a010f01"
      },
      "source": [
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "DATA_DIR = '/content/gdrive/MyDrive/WorldModelsExperiments/carracing/Data'\n",
        "\n",
        "filelist = os.listdir(DATA_DIR)\n",
        "filelist.sort()\n",
        "filelist = filelist[195:]\n",
        "\n",
        "# print(filelist)\n",
        "\n",
        "data = np.load(DATA_DIR + '/' + filelist[1])\n",
        "game_frames = data['obs']\n",
        "game_frames = game_frames.astype(np.float32)/255.0\n",
        "\n",
        "# def fr(frames):\n",
        "#   x = np.shape(frames)[0]\n",
        "#   i = 0\n",
        "#   while i <= x:\n",
        "#     yield frames[i]\n",
        "#     i += i \n",
        "\n",
        "\n",
        "fig = plt.figure('hh')\n",
        "img = [[plt.imshow(frame)] for frame in game_frames]\n",
        "# def animate(i):\n",
        "#   return plt.imshow(i)\n",
        "\n",
        "# anim = animation.FuncAnimation(fig, animate, fr(game_frames[0:10]), interval = 20, blit = True)\n",
        "anim = animation.ArtistAnimation(fig, img, interval = 20, blit = True, repeat_delay=0)\n",
        "anim.save('random_trail.mp4')\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}